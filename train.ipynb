{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPN4GsCpZC4W"
      },
      "source": [
        "# Preliminary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKNTf7L4b2z7"
      },
      "source": [
        "Here we install all imports and other necessary components.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1H3gELF5H9o"
      },
      "source": [
        "## Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccCEcC7sI89U",
        "outputId": "69ccc84a-99bf-439e-fe3d-3cf05d39cd9b"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/WongKinYiu/yolov7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMR9UH9jPyNX"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOLOR ðŸš€ v0.1-128-ga207844 torch 2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4080 SUPER, 15951.875MB)\n",
            "\n",
            "Namespace(weights='./yolov7.pt', cfg='yolov7/cfg/training/yolov7.yaml', data='./yolo_files/config_default.yaml', hyp='./yolov7/data/hyp.scratch.p5.yaml', epochs=300, batch_size=16, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='train_default', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/train_default2', total_batch_size=16)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
            "/home/jan/Documents/code/CV-Fish-Abundance/./yolov7/train.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  run_id = torch.load(weights, map_location=device).get('wandb_id') if weights.endswith('.pt') and os.path.isfile(weights) else None\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/jan/Documents/code/CV-Fish-Abundance/./yolov7/train.py\", line 616, in <module>\n",
            "    train(hyp, opt, device, tb_writer)\n",
            "  File \"/home/jan/Documents/code/CV-Fish-Abundance/./yolov7/train.py\", line 80, in train\n",
            "    assert len(names) == nc, '%g names found for nc=%g dataset in %s' % (len(names), nc, opt.data)  # check\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: 16 names found for nc=80 dataset in ./yolo_files/config_default.yaml\n"
          ]
        }
      ],
      "source": [
        "!python \"./yolov7/train.py\" --epochs 300 --device 0 --batch-size 16 --data \"./yolo_files/config_default.yaml\" --img 640 640 --cfg \"yolov7/cfg/training/yolov7.yaml\" --weights \"./yolov7.pt\" --name train_default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 240"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python \"./yolov7/train.py\" --epochs 300 --device 0 --batch-size 32 --data \"./yolo_files/config_240.yaml\" --img 240 240 --cfg \"yolov7/cfg/training/yolov7.yaml\" --weights \"./yolov7.pt\" --name train_240 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## edge detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python \"./yolov7/train.py\" --epochs 100 --workers 8 --device 0 --batch-size 16 --data \"./yolo_files/config_edge.yaml\" --img 640 640 --cfg \"./yolo_files/yolov7_custom_fishdetection.yaml\" --weights \"./yolo_files/best.pt\" --name train_edge --hyp \"./yolov7/data/hyp.scratch.p5.yaml\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## hyper tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOLOR ðŸš€ v0.1-128-ga207844 torch 2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4080 SUPER, 15951.875MB)\n",
            "\n",
            "Namespace(weights='runs/train/train_hyper/weights/last.pt', cfg='./yolo_files/yolov7_custom_fishdetection.yaml', data='./yolo_files/config_hyper.yaml', hyp='./yolo_files/hyp.scratch.custom_fishdetection.yaml', epochs=300, batch_size=16, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='train_hyper', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/train_hyper2', total_batch_size=16)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.95, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.7, warmup_bias_lr=0.1, box=0.1, cls=0.4, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=3.0, fl_gamma=0.5, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=5.0, translate=0.2, scale=0.5, shear=0.1, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.1, paste_in=0.15, loss_ota=1\n",
            "/home/jan/Documents/code/CV-Fish-Abundance/./yolov7/train.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  run_id = torch.load(weights, map_location=device).get('wandb_id') if weights.endswith('.pt') and os.path.isfile(weights) else None\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "/home/jan/Documents/code/CV-Fish-Abundance/./yolov7/train.py:87: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(weights, map_location=device)  # load checkpoint\n",
            "Overriding model.yaml nc=80 with nc=16\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1    115066  models.yolo.IDetect                     [16, [[66, 59, 87, 77, 113, 110], [125, 172, 182, 134, 186, 221], [277, 205, 354, 301, 499, 518]], [256, 512, 1024]]\n",
            "/home/jan/Documents/code/CV-Fish-Abundance/cv_project/lib/python3.12/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3609.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 415 layers, 37277466 parameters, 37277466 gradients, 105.4 GFLOPS\n",
            "\n",
            "Transferred 564/566 items from runs/train/train_hyper/weights/last.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "/home/jan/Documents/code/CV-Fish-Abundance/yolov7/utils/datasets.py:392: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  cache, exists = torch.load(cache_path), True  # load\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'train_combined_hyper/#201011150930_0.cache' images and labels..\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'val_combined/#201103060650_1.cache' images and labels... 9487 fou\u001b[0m\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 2.90, Best Possible Recall (BPR) = 0.8685. Attempting to improve anchors, please wait...\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 9153 points...\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.33: 1.0000 best possible recall, 6.27 anchors past thr\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=640, metric_all=0.473/0.834-mean/best, past_thr=0.583-mean: 24,22,  35,30,  35,50,  51,40,  71,51,  57,72,  90,87,  136,114,  205,213\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8387: 100%|â–ˆ| 1\u001b[0m\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.33: 1.0000 best possible recall, 6.38 anchors past thr\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=640, metric_all=0.482/0.839-mean/best, past_thr=0.589-mean: 24,22,  32,28,  46,36,  37,50,  61,47,  56,69,  85,80,  133,105,  207,196\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
            "\n",
            "/home/jan/Documents/code/CV-Fish-Abundance/./yolov7/train.py:299: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler(enabled=cuda)\n",
            "Image sizes 640 train, 640 test\n",
            "Using 8 dataloader workers\n",
            "Logging results to runs/train/train_hyper2\n",
            "Starting training for 300 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "  0%|                                                   | 0/563 [00:00<?, ?it/s]/home/jan/Documents/code/CV-Fish-Abundance/./yolov7/train.py:360: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(enabled=cuda):\n",
            "     0/299     2.26G    0.1128 0.0007987  0.001095    0.1147        19       640\n",
            "/home/jan/Documents/code/CV-Fish-Abundance/cv_project/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n",
            "               Class      Images      Labels           P           R      mAP@.5\n",
            "                 all       21742       14179      0.0973      0.0202     0.00231     0.00055\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     1/299     13.5G    0.1131 0.0008049  0.001074    0.1149        37       640\n",
            "               Class      Images      Labels           P           R      mAP@.5\n",
            "                 all       21742       14179      0.0979      0.0192     0.00237     0.00057\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     2/299     15.4G     0.113 0.0008001  0.001087    0.1149        21       640\n",
            "               Class      Images      Labels           P           R      mAP@.5\n",
            "                 all       21742       14179      0.0973      0.0199     0.00225    0.000527\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     3/299     15.4G    0.1145 0.0008036  0.001111    0.1164        30       640\n",
            "               Class      Images      Labels           P           R      mAP@.5\n",
            "                 all       21742       14179       0.097      0.0199     0.00214    0.000503\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     4/299     15.4G    0.1127 0.0007891 0.0009213    0.1144        22       640\n",
            "               Class      Images      Labels           P           R      mAP@.5\n",
            "                 all       21742       14179      0.0967      0.0197     0.00209    0.000485\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     5/299     15.4G    0.1147 0.0008389  0.001043    0.1166        19       640^C\n",
            "     5/299     15.4G    0.1147 0.0008389  0.001043    0.1166        19       640\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/jan/Documents/code/CV-Fish-Abundance/./yolov7/train.py\", line 616, in <module>\n",
            "    train(hyp, opt, device, tb_writer)\n",
            "  File \"/home/jan/Documents/code/CV-Fish-Abundance/./yolov7/train.py\", line 388, in train\n",
            "    pbar.set_description(s)\n",
            "  File \"/home/jan/Documents/code/CV-Fish-Abundance/cv_project/lib/python3.12/site-packages/tqdm/std.py\", line 1382, in set_description\n",
            "    def set_description(self, desc=None, refresh=True):\n",
            "\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python \"./yolov7/train.py\" --epochs 300 --device 0 --batch-size 16 --data \"./yolo_files/config_hyper.yaml\" --img 640 640 --cfg \"./yolo_files/yolov7_custom_fishdetection.yaml\" --weights \"runs/train/train_hyper/weights/last.pt\" --name train_hyper --hyp \"./yolo_files/hyp.scratch.custom_fishdetection.yaml\" --resume"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python \"./yolov7/train.py\" --epochs 100 --workers 8 --device 0 --batch-size 16 --data \"./yolo_files/config_default.yaml\" --img 640 640 --cfg \"yolov7/cfg/training/yolov7.yaml\" --weights \"./runs/train/train_hyper/weights/best.pt\" --name train_default --hyp \"./yolov7/data/hyp.scratch.p5.yaml\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(weights=['./yolo_files/best_999.pt'], data='./yolo_files/config_default.yaml', batch_size=16, img_size=640, conf_thres=0.001, iou_thres=0.65, task='val', device='0', single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project='runs/test', name='test_default', exist_ok=False, no_trace=False, v5_metric=False)\n",
            "YOLOR ðŸš€ v0.1-128-ga207844 torch 2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4080 SUPER, 15951.875MB)\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/jan/Documents/code/CV-Fish-Abundance/yolov7/utils/google_utils.py\", line 26, in attempt_download\n",
            "    assets = [x['name'] for x in response['assets']]  # release assets\n",
            "                                 ~~~~~~~~^^^^^^^^^^\n",
            "KeyError: 'assets'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/jan/Documents/code/CV-Fish-Abundance/./yolov7/test.py\", line 319, in <module>\n",
            "    test(opt.data,\n",
            "  File \"/home/jan/Documents/code/CV-Fish-Abundance/./yolov7/test.py\", line 58, in test\n",
            "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jan/Documents/code/CV-Fish-Abundance/yolov7/models/experimental.py\", line 251, in attempt_load\n",
            "    attempt_download(w)\n",
            "  File \"/home/jan/Documents/code/CV-Fish-Abundance/yolov7/utils/google_utils.py\", line 31, in attempt_download\n",
            "    tag = subprocess.check_output('git tag', shell=True).decode().split()[-1]\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^\n",
            "IndexError: list index out of range\n"
          ]
        }
      ],
      "source": [
        "!python \"./yolov7/test.py\" --device 0 --batch-size 16 --data \"./yolo_files/config_default.yaml\" --img 640 --weights \"./yolo_files/best.pt\" --name test_default"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "SPN4GsCpZC4W",
        "BOgY7NnkQO4S",
        "bB9eG7qbV6jl",
        "hfFX_FAOYTQt",
        "xdYij-suZLWQ",
        "xPNG9tgHZa18",
        "3NNPM9OqZoGw",
        "2GFUTgDpZwlJ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cv_project",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
